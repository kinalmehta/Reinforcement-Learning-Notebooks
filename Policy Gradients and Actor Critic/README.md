
# Policy Gradients and Actor Critic

Here I have implemented incremental changes from Vanilla Policy Gradient or REINFORCE to Actor-Critic and other latest developments as mentioned in [3].

#### To-Do
- [x] REINFORCE or Policy Gradient(PG) [1,2,3] [notebook](PolicyGradient_torch.ipynb)
- [x] PG with reward-to-go [2] [notebook](PolicyGradient_torch.ipynb)
- [x] PG with learned Baseline (why not call it Actor-Critic) [notebook](ActorCritic_torch.ipynb)
- [ ] A3C/Synchronous A2C [3,4]

#### References
1. https://arxiv.org/pdf/1604.06778.pdf
2. https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html
3. https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html
4. https://danieltakeshi.github.io/2018/06/28/a2c-a3c/
