
# My path in RL

Starting with reinforcement learning gets really overwhelming for a beginner. There is no clear visible [path to follow](./suggested_path_in_RL.md) and hence you have to experiment a lot to carve out your own learning path. <br>
Here I'll be sharing my own experience and the steps I took to get started, learn, and move towards advanced topics to application development or research.<br>

#### 1. Introduction to Reinforcement Learning -  David Silver's UCL lectures [link](https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ) (October 2018)

- This is the first course I started with. It gives a great introduction to classical RL in tabular form. This course if enough to equip you with all the **conceptual and theoretical** knowledge. It is a good place to develop your understanding.
- I personally didn't work on any code with this course.

#### 2. UC Berkley Deep RL Course [link](http://rail.eecs.berkeley.edu/deeprlcourse/) (January 2019)

- After finishing the first course, I was confident that I could go through this course for Deep RL. I was terribly mistaken.
- I started with the videos and was also doing the assignments along.
- Though I was able to understand the videos, it was really challenging for me to implement the 2nd assignment.
- This was probably because I didn't implement anything in the previous course. This was a great eye-opener.

**BREAK:** Next 6 months I took a break from RL and focused my attention on Deep Learning. Was I scared of failing?

#### 3. Udacity's Deep Reinforcement Learning Nanodegree [link](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) (August 2019)

- I had participated in one of the scholarship challenges on Udacity and got scholarship for this course. It is a fantastic course. A lot of my concepts got revised. It also help me get a better understanding of the classical control algorithms. This is more of a **practical** course. You have to implement various algorithms explained in their videos immediately. Though not a compulsion, its worth investing your time in the implementations as it gives your confidence about your own understanding.
- In case you **cannot afford to purchase** this course, you can try for scholarships. You can also use their [Github Repository](https://github.com/udacity/deep-reinforcement-learning) and try working with the code samples and finishing the projects even without the videos. The repository and the notebooks are well documented and should suffice.
- Not to forget this course has a pre-requisite that you have decent knowledge of Deep Learning/Neural Networks. I was able to glide through this course as I had already done [Deep Learning Nanodegree](https://www.udacity.com/course/deep-learning-nanodegree--nd101) as part of the same scholarship plus I also had 1 year of industry experience in DL.

#### 4. Reinforcement Learning Specialization by University of Alberta [link](https://www.coursera.org/specializations/reinforcement-learning) (January 2020)

- This course along with the [Reinforcement Learning Textbook](http://incompleteideas.net/book/RLbook2018.pdf) is the perfect combination for a beginner.
- I started with this course as I was applying for MS CS at University of Alberta and thought it'll be a good thing to have done their own certification.
- As I had already gone through David Silver's course, my basics were already pretty strong. This course worked as a great revision, and I also implemented several algorithms as assignments.
- It helped me strengthen my fundamentals and get a better understanding with the implementations in various settings.

#### 5. Reinforcement Learning Textbook by Richard Sutton and Andrew Barto [link](http://incompleteideas.net/book/RLbook2018.pdf) (January 2020)

- This is the only book you would need for beginning in RL.
- As there is no similar book for Deep RL, it has to be learned through blogs, online lectures and papers.
- I followed this book along with the RL Specialization. That was the best combination for clearing the fundamentals.

#### 6. OpenAI SpinningUp [link](https://spinningup.openai.com/en/latest/index.html) (February 2020)

- After clearing the basic concepts, I started with Deep RL again with SpinningUp.
- Going through the introduction gave me a better understanding of key concepts and Policy Gradients. I was able to derive the proof of PG explained here.
- Next, I started with Spinning Up as a Deep RL Researcher. One of the most important section here is "Learn by Doing". I implemented minimalistic versions of various algorithms as mentioned here. This is the part where this repository was born.

#### 7. Neuro-Dynamic Programming by Dimitri Bertsekas and John Tsitsiklis [link](http://athenasc.com/ndpbook.html) (March 2020)

- I started reading this book with SpinningUp as it was mentioned in David Silver's class.
- It gives a different perspective, but the concepts are quite similar to Sutton and Barto's book.
- I am still reading this book, so will update more details of what I gained/learned from this book.
